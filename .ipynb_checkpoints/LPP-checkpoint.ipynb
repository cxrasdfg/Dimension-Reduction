{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "from sklearn import datasets,decomposition,manifold\n",
    "from sklearn import neighbors\n",
    "import scipy.io as sio\n",
    "import scipy\n",
    "import struct\n",
    "import math\n",
    "import mnist\n",
    "import pylab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib inline\n",
    "#%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_score(train_data, train_label, test_data, test_label):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors = 1)  \n",
    "    knn.fit(train_data, train_label)\n",
    "    s = knn.score(test_data, test_label)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LPP(data, k, d):\n",
    "    '''\n",
    "    data is the original data. m*n(m=samples, n=dimensions)\n",
    "    '''\n",
    "    data = np.matrix(data)\n",
    "    N = data.shape[0]\n",
    "    Dim = data.shape[1]\n",
    "    \n",
    "    # step 1\n",
    "    # find the nearest neighbors (k). Here we get the distance from (x-y)^2\n",
    "    # distance N*N\n",
    "   \n",
    "    data_tmp = np.sum(np.multiply(data, data), axis=1)\n",
    "    distance=np.mat(data_tmp + data_tmp.T - 2*data*data.T)\n",
    "    sort_index = np.argsort(distance,axis=1)\n",
    "    # k nearest neibors\n",
    "    neibors = sort_index[:,1:k+1]\n",
    "    \n",
    "    # step 2\n",
    "    # weights\n",
    "    \n",
    "    W=np.zeros([N,N])\n",
    "    D=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in neibors[i].A[0]:\n",
    "            W[i, j] = math.exp(-(np.linalg.norm(data[j]-data[i],ord=2))/2)\n",
    "            W[j, i] = W[i, j]  \n",
    "    for i in range(N):\n",
    "        for j in neibors[i].A[0]:\n",
    "            D[i, i] +=W[i, j]  \n",
    "    \n",
    "    # Step 3\n",
    "    # mappings \n",
    "    \n",
    "    L=D-W\n",
    "    X = np.dot(np.dot(data.T, D), data)\n",
    "    X = X + 0.000000001 * np.eye(Dim)\n",
    "    X = np.dot(X.I, np.dot(np.dot(data.T, L), data))\n",
    "    eigenValues, eigenVectors=scipy.linalg.eig(X)\n",
    "    eigenValuesIndex = np.argsort(eigenValues)\n",
    "    mapping = eigenVectors[:, eigenValuesIndex[0:d]].T\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=sio.loadmat(\"orl_faces/32_32/ORL_32x32.mat\")\n",
    "face = data['fea']/255\n",
    "label = data['gnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LPP_faces():\n",
    "    matfn = 'orl_faces/32_32/3Train/2.mat'\n",
    "    index = sio.loadmat(matfn)\n",
    "    testIdx = index['testIdx'] -1    \n",
    "    trainIdx = index['trainIdx'] -1  \n",
    "    trainface = face[trainIdx]\n",
    "    mapping = LPP(trainface, 10, 8, 10)\n",
    "    tmp=mapping[2]\n",
    "    tmp=tmp.reshape(32, 32).astype(float)\n",
    "    pylab.imshow(tmp.T, cmap='gray', interpolation='hamming')\n",
    "    pylab.show()\n",
    "    \n",
    "# LPP_faces1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orl_scatters():\n",
    "    # the first 100 samples\n",
    "    face100 = np.squeeze(face)[:100]\n",
    "    label100 = label.reshape(400)[:100]\n",
    "    mapping = LPP(face100, 10, 2, 10)\n",
    "    low_data = np.dot(mapping, face100.T).T\n",
    "    \n",
    "    fig = plt.figure(figsize=(7,5))\n",
    "    plotwindow = fig.add_subplot(111)\n",
    "    a = np.array(low_data)\n",
    "\n",
    "    # draw the scatters\n",
    "    color = ['green','dodgerblue','chartreuse','turquoise','orange','coral','salmon','darkgray','darkred','mediumpurple']\n",
    "    for j in range(len(low_data)):\n",
    "        plt.scatter(a[j][0], a[j][1],s=40, c=color[label100[j]-1])\n",
    "    plt.show()\n",
    "#orl_scatters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(data,dimensions):\n",
    "    '''\n",
    "    data is the original data setï¼Œrows are samples of data,columns are the features\n",
    "    '''\n",
    "\n",
    "    # making data zero-means\n",
    "    average = np.mean(data,0)\n",
    "    data_zero = np.mat(data-average)\n",
    "    \n",
    "    #covariance\n",
    "    covariance = np.cov(data_zero,rowvar=False)\n",
    "    \n",
    "    #eigenvalues\n",
    "    eig_var,eig_vec = np.linalg.eig(covariance)\n",
    "    \n",
    "    \n",
    "    #from the numpy doc, the eig_var may not be ordered.\n",
    "    sort_eig = np.argsort(-eig_var)\n",
    "    #return the index that make a sorted array\n",
    "\n",
    "    #so we got the sorted eig_var\n",
    "    sort_eig = sort_eig[:dimensions]\n",
    "    principal_vec = np.mat(eig_vec[:,sort_eig])\n",
    "    \n",
    "    return principal_vec, np.dot(data_zero, principal_vec)\n",
    "\n",
    "def Laplacianfaces(data, k, d, t):\n",
    "    \n",
    "    data = np.matrix(data)\n",
    "    N = data.shape[0]\n",
    "    D = data.shape[1]\n",
    "    \n",
    "    # step 1\n",
    "    # find the nearest neighbors (k). Here we get the distance from (x-y)^2\n",
    "    # distance N*N\n",
    "   \n",
    "    data_tmp = np.sum(np.multiply(data, data), axis=1)\n",
    "    distance=np.mat(data_tmp + data_tmp.T - 2*data*data.T)\n",
    "    sort_index = np.argsort(distance,axis=1)\n",
    "    # k nearest neibors\n",
    "    neibors = sort_index[:,1:k+1]\n",
    "    \n",
    "    # step 2\n",
    "    # weights\n",
    "    \n",
    "    W=np.zeros([N,N])\n",
    "    D=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in neibors[i].A[0]:\n",
    "            W[i, j] = math.exp(-distance[i, j]/t)\n",
    "            D[i, i] +=W[i, j]  \n",
    "            \n",
    "    \n",
    "    # Step 3\n",
    "    # mappings \n",
    "    \n",
    "    L=D-W\n",
    "    X = np.dot(np.dot(data.T, D), data)\n",
    "    X = np.dot(X.I,np.dot(np.dot(data.T, L), data))\n",
    "    eigenValues, eigenVectors=np.linalg.eig(X)\n",
    "    eigenValuesIndex = np.argsort(eigenValues)\n",
    "    mapping = np.mat(eigenVectors[:, eigenValuesIndex[0:d]])\n",
    "    \n",
    "    mapping_PCA = PCA(data, d)\n",
    "    \n",
    "    return np.dot(mapping_PCA, mapping.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LP_faces():\n",
    "    matfn = 'faces/3Train/2.mat'\n",
    "    index = sio.loadmat(matfn)\n",
    "    testIdx = index['testIdx'] -1    \n",
    "    trainIdx = index['trainIdx'] -1  \n",
    "    trainface = face[trainIdx]\n",
    "    mapping = Laplacianfaces(trainface, 5, 8, 10)\n",
    "    tmp=mapping[2]\n",
    "    tmp=tmp.reshape(32, 32).astype(float)\n",
    "    pylab.imshow(tmp.T, cmap='gray', interpolation='hamming')\n",
    "    pylab.show()\n",
    "    \n",
    "#LP_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LPscore(l):\n",
    "    ## 32 * 32 ORL_faces \n",
    "    s=0.0\n",
    "    for i in range(50):\n",
    "        matfn = 'faces/'+str(l)+'Train/'+str(i+1)+'.mat'\n",
    "        index = sio.loadmat(matfn)\n",
    "        testIdx = index['testIdx'] -1  \n",
    "        trainIdx = index['trainIdx'] -1\n",
    "        trainface = face[trainIdx]\n",
    "        trainlabel = label[trainIdx].reshape(l*40,1)\n",
    "        trainface = np.squeeze(trainface) \n",
    "        \n",
    "        testface = face[testIdx]\n",
    "        testlabel = label[testIdx].reshape(400-l*40,1)\n",
    "        testface = np.squeeze(testface)  \n",
    "       \n",
    "        mapping = Laplacianfaces(trainface, 10, 150, 10)\n",
    "        traindata = np.dot(mapping, trainface.T)\n",
    "        testdata = np.dot(mapping, testface.T)\n",
    "        s+=knn_score(traindata.T, trainlabel, testdata.T, testlabel)\n",
    "    return s/50\n",
    "\n",
    "# LP_score = LPscore(3)\n",
    "# print(LP_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twoD_LPP(data, k, n_1, n_2, l_1, l_2):\n",
    "    '''\n",
    "    data is the original data. m*n(m=samples, n=dimensions)\n",
    "    '''\n",
    "    data = np.matrix(data)\n",
    "    N = data.shape[0]\n",
    "    Dim = data.shape[1]\n",
    "    \n",
    "    # step 1\n",
    "    # find the nearest neighbors (k). Here we get the distance from (x-y)^2\n",
    "    # distance N*N\n",
    "   \n",
    "    data_tmp = np.sum(np.multiply(data, data), axis=1)\n",
    "    distance=np.mat(data_tmp + data_tmp.T - 2*data*data.T)\n",
    "    sort_index = np.argsort(distance,axis=1)\n",
    "    # k nearest neibors\n",
    "    neibors = sort_index[:,1:k+1]\n",
    "    \n",
    "    # step 2\n",
    "    # weights\n",
    "    \n",
    "    W=np.zeros([N,N])\n",
    "    D=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in neibors[i].A[0]:\n",
    "            W[i, j] = math.exp(-(np.linalg.norm(data[j]-data[i],ord=2))/2)\n",
    "            W[j, i] = W[i, j]  \n",
    "   \n",
    "    \n",
    "    # Step 3\n",
    "    # mappings \n",
    "    \n",
    "    # initial L\n",
    "    L = np.ones((n_1, l_1))\n",
    "    \n",
    "    for i in range(N):\n",
    "        A_i = data[i, :].reshape((n_1, n_2))\n",
    "        for j in range(N):\n",
    "            A_j = data[j, :].reshape((n_1, n_2))\n",
    "            R_L = W[i, j]*np.dot(np.dot(np.dot((A_i-A_j).T, L), L.T), (A_i-A_j))\n",
    "            R_R = np.dot(np.dot(np.dot((A_i-A_j).T, L), L.T), (A_i-A_j))\n",
    "            \n",
    "    eigenValues, eigenVectors=scipy.linalg.eig(R_L, R_R)\n",
    "    eigenValuesSort=np.argsort(eigenValues)\n",
    "    R=np.mat(eigenVectors[:,eigenValuesSort[0:l_2]])\n",
    "    \n",
    "    for i in range(N):\n",
    "        A_i = data[i, :].reshape((n_1, n_2))\n",
    "        for j in range(N):\n",
    "            A_j = data[j, :].reshape((n_1, n_2))\n",
    "            L_L = W[i, j]*np.dot(np.dot(np.dot((A_i-A_j).T, L), L.T), (A_i-A_j))\n",
    "            L_R = np.dot(np.dot(np.dot((A_i-A_j).T, L), L.T), (A_i-A_j))\n",
    "\n",
    "    eigenValues, eigenVectors=scipy.linalg.eig(L_L, L_R)\n",
    "    eigenValuesSort=np.argsort(eigenValues)\n",
    "    L=np.mat(eigenVectors[:,eigenValuesSort[0:l_1]])\n",
    "    \n",
    "    return L, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Kernel_LPP(data, k, d):\n",
    "    '''\n",
    "    data is the original data. m*n(m=samples, n=dimensions)\n",
    "    '''\n",
    "    data = np.matrix(data)\n",
    "    N = data.shape[0]\n",
    "    Dim = data.shape[1]\n",
    "    \n",
    "    # step 1\n",
    "    # find the nearest neighbors (k). Here we get the distance from (x-y)^2\n",
    "    # distance N*N\n",
    "   \n",
    "    data_tmp = np.sum(np.multiply(data, data), axis=1)\n",
    "    distance=np.mat(data_tmp + data_tmp.T - 2*data*data.T)\n",
    "    sort_index = np.argsort(distance,axis=1)\n",
    "    # k nearest neibors\n",
    "    neibors = sort_index[:,1:k+1]\n",
    "    \n",
    "    # step 2\n",
    "    # weights\n",
    "    \n",
    "    W=np.zeros([N,N])\n",
    "    D=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in neibors[i].A[0]:\n",
    "            W[i, j] = math.exp(-(np.linalg.norm(data[j]-data[i],ord=2))/2)\n",
    "            W[j, i] = W[i, j]  \n",
    "    for i in range(N):\n",
    "        for j in neibors[i].A[0]:\n",
    "            D[i, i] +=W[i, j]  \n",
    "    \n",
    "    # Step 3\n",
    "    # mappings \n",
    "    K=np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i, j] = math.exp(-(np.linalg.norm(data[j]-data[i],ord=2))/2)\n",
    "    \n",
    "    \n",
    "    L=D-W\n",
    "    ei_L=np.dot(np.dot(K, L), K)\n",
    "    ei_R=np.dot(np.dot(K, D), K)\n",
    "    eigenValues, eigenVectors=scipy.linalg.eig(ei_L, ei_R)\n",
    "    eigenValuesSort=np.argsort(eigenValues)\n",
    "    mapping = eigenVectors[:, eigenValuesSort[0:d]]\n",
    "    \n",
    "    return mapping, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangzhenyu/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py:531: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/huangzhenyu/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:433: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78125\n",
      "0.775\n",
      "0.8125\n",
      "0.825\n",
      "0.8\n",
      "0.825\n",
      "0.75625\n",
      "0.8125\n",
      "0.7875\n",
      "0.8125\n",
      "0.79375\n",
      "0.7875\n",
      "0.79375\n",
      "0.775\n",
      "0.725\n",
      "0.75625\n",
      "0.7375\n",
      "0.79375\n",
      "0.775\n",
      "0.8\n",
      "0.81875\n",
      "0.76875\n",
      "0.74375\n",
      "0.75625\n",
      "0.7625\n",
      "0.75625\n",
      "0.78125\n",
      "0.7875\n",
      "0.7625\n",
      "0.7875\n",
      "0.76875\n",
      "0.78125\n",
      "0.76875\n",
      "0.76875\n",
      "0.76875\n",
      "0.80625\n",
      "0.75\n",
      "0.78125\n",
      "0.7875\n",
      "0.7875\n",
      "0.7625\n",
      "0.8\n",
      "0.81875\n",
      "0.7875\n",
      "0.775\n",
      "0.75\n",
      "0.78125\n",
      "0.725\n",
      "0.74375\n",
      "0.775\n",
      "s 0.77875\n"
     ]
    }
   ],
   "source": [
    "def LPPscore(l):\n",
    "    ## 32 * 32 ORL_faces \n",
    "    s=0.0\n",
    "    for i in range(50):\n",
    "        matfn = 'orl_faces/32_32/'+str(l)+'Train/'+str(i+1)+'.mat'\n",
    "        index = sio.loadmat(matfn)\n",
    "        testIdx = index['testIdx'] -1  \n",
    "        trainIdx = index['trainIdx'] -1\n",
    "        \n",
    "\n",
    "##LPP      \n",
    "#         trainface = np.squeeze(face[trainIdx])\n",
    "#         trainlabel = np.squeeze(label[trainIdx])\n",
    "#         testface = np.squeeze(face[testIdx])\n",
    "#         testlabel = np.squeeze(label[testIdx]) \n",
    "#         mapping = LPP(trainface, 2, 100)\n",
    "#         traindata = np.dot(mapping, trainface.T)\n",
    "#         testdata = np.dot(mapping, testface.T)\n",
    "#         tmp=knn_score(traindata.T, trainlabel, testdata.T, testlabel)\n",
    "        \n",
    "## 2D LPP\n",
    "        mapping, face_pca = PCA(np.squeeze(face), 225)\n",
    "        \n",
    "        trainface = np.squeeze(face_pca[trainIdx])\n",
    "        trainlabel = np.squeeze(label[trainIdx])\n",
    "        testface = np.squeeze(face_pca[testIdx])\n",
    "        testlabel = np.squeeze(label[testIdx])\n",
    "\n",
    "       \n",
    "        L, R= twoD_LPP(trainface, 2, 15, 15, 7, 7)\n",
    "        \n",
    "        traindata = []\n",
    "        testdata = []\n",
    "        for i in range(trainface.shape[0]):\n",
    "            traindata.append(np.dot(np.dot(L.T, trainface[i].reshape(15, 15)), R).A[0])\n",
    "        for i in range(testface.shape[0]):\n",
    "            testdata.append(np.dot(np.dot(L.T, testface[i].reshape(15, 15)), R).A[0])\n",
    "        \n",
    "        tmp=knn_score(traindata, trainlabel, testdata, testlabel)\n",
    "\n",
    "## kernel\n",
    "#         trainface = np.squeeze(face[trainIdx])\n",
    "#         trainlabel = np.squeeze(label[trainIdx])\n",
    "#         testface = np.squeeze(face[testIdx])\n",
    "#         testlabel = np.squeeze(label[testIdx])\n",
    "       \n",
    "#         mapping, K_train= Kernel_LPP(trainface, 10, 50)\n",
    "\n",
    "#         K_test = np.zeros((trainface.shape[0], testface.shape[0]))\n",
    "#         for i in range(trainface.shape[0]):\n",
    "#             for j in range(testface.shape[0]):\n",
    "#                 K_test[i, j]=math.exp(-(np.linalg.norm(trainface[i]-testface[j],ord=2))/2)\n",
    "        \n",
    "#         traindata = np.dot(mapping.T, K_train)\n",
    "#         testdata = np.dot(mapping.T, K_test)\n",
    "#         tmp=knn_score(traindata.T, trainlabel, testdata.T, testlabel)\n",
    "        \n",
    "        \n",
    "        print(tmp)\n",
    "        s+=tmp\n",
    "    return s/50\n",
    "\n",
    "LPP_score = LPPscore(6)\n",
    "print(\"s\", LPP_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
