{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import struct\n",
    "from andylearn import mnist\n",
    "import sklearn.neighbors as nb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(data,dimensions):\n",
    "    '''\n",
    "    data is the original data set，rows are samples of data,columns are the features\n",
    "    '''\n",
    "\n",
    "    # making data zero-means\n",
    "    average = np.mean(data,0)\n",
    "    data = np.mat(data-average)\n",
    "    \n",
    "    #covariance\n",
    "    covariance = np.dot(data.T, data)\n",
    "    \n",
    "    #eigenvalues\n",
    "    eig_var,eig_vec = np.linalg.eig(covariance)\n",
    "    \n",
    "    \n",
    "    #from the numpy doc, the eig_var may not be ordered.\n",
    "    sort_eig = np.argsort(-eig_var)\n",
    "    #return the index that make a sorted array\n",
    "\n",
    "    #so we got the sorted eig_var\n",
    "    sort_eig = sort_eig[:dimensions]\n",
    "    principal_vec = eig_vec[:,sort_eig]\n",
    "    \n",
    "   \n",
    "    low_data = np.dot(data, principal_vec)\n",
    "    \n",
    "    return low_data, principal_vec, average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVD(data,dimensions):\n",
    "    '''\n",
    "    data is the original data set，rows are samples of data,columns are the features\n",
    "    '''\n",
    "\n",
    "    # making data zero-means\n",
    "    average = np.mean(data,0)\n",
    "    data_zero = data-average\n",
    "    \n",
    "    #covariance\n",
    "    covariance = np.cov(data_zero,rowvar=False)\n",
    "    \n",
    "    u,s,v = np.linalg.svd(data)\n",
    "    #s is sorted in descending order.\n",
    "    principal_vec = v.T[:,:dimensions]\n",
    "    low_data = np.mat(data_zero) * np.mat(principal_vec)\n",
    "    \n",
    "    return low_data, principal_vec, average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">the data format  \n",
    "\n",
    "    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "\n",
    "    [offset] [type]          [value]          [description] \n",
    "    0000     32 bit integer  0x00000803(2051) magic number \n",
    "    0004     32 bit integer  60000            number of images \n",
    "    0008     32 bit integer  28               number of rows \n",
    "    0012     32 bit integer  28               number of columns \n",
    "    0016     unsigned byte   ??               pixel \n",
    "    0017     unsigned byte   ??               pixel \n",
    "    ........ \n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "    \n",
    ">so there are 4*32 bits we shuold take care of. And the rest is actually what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the first 2K training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_mnist_training() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-24bd43a9d1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mnist_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlow_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_mnist_training() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "data, labels = mnist.load_mnist_training(\"data/mnist/train-images\", \"data/mnist/test-images\", 2000)\n",
    "\n",
    "low_data, mapping, average = PCA(data,5)\n",
    "\n",
    "fig = plt.figure()\n",
    "plotwindow = fig.add_subplot(111)\n",
    "a = np.array(low_data)\n",
    "\n",
    "# draw the scatters\n",
    "color = ['yellowgreen','yellow','chartreuse','turquoise','orange','coral','salmon','darkgray','skyblue','mediumpurple']\n",
    "for j in range(len(low_data)):\n",
    "    \n",
    "    plt.scatter(a[j][0],a[j][1],c=color[labels[j]],s=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data loading\n",
      "training data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangzhenyu/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py:531: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/huangzhenyu/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:433: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features 2\n",
      "KNN score 0.385\n",
      "features 3\n",
      "KNN score 0.436\n",
      "features 4\n",
      "KNN score 0.535\n",
      "features 5\n",
      "KNN score 0.622\n",
      "features 6\n",
      "KNN score 0.725\n",
      "features 7\n",
      "KNN score 0.758\n",
      "features 8\n",
      "KNN score 0.793\n",
      "features 9\n",
      "KNN score 0.816\n",
      "features 10\n",
      "KNN score 0.82\n",
      "features 11\n",
      "KNN score 0.816\n",
      "features 12\n",
      "KNN score 0.853\n",
      "features 13\n",
      "KNN score 0.858\n",
      "features 14\n",
      "KNN score 0.855\n",
      "features 15\n",
      "KNN score 0.872\n",
      "features 16\n",
      "KNN score 0.886\n",
      "features 17\n",
      "KNN score 0.879\n",
      "features 18\n",
      "KNN score 0.881\n",
      "features 19\n",
      "KNN score 0.875\n",
      "features 20\n",
      "KNN score 0.876\n",
      "features 21\n",
      "KNN score 0.88\n"
     ]
    }
   ],
   "source": [
    "data, labels = mnist.load_mnist_training(2000)\n",
    "\n",
    "for i in range(2,22):\n",
    "    low_data = PCA(data,i)\n",
    "    knn = nb.KNeighborsClassifier(n_neighbors = 1)  \n",
    "    knn.fit(low_data[:1000], labels[:1000])\n",
    "    s = knn.score(low_data[1000:2000], labels[1000:2000])\n",
    "    print(\"features\",i)\n",
    "    print(\"KNN score\",s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the first 2K test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, labels = mnist.load_mnist_testing(2000)     \n",
    "low_data = PCA(data,5)\n",
    "\n",
    "fig = plt.figure()\n",
    "plotwindow = fig.add_subplot(111)\n",
    "a = np.array(low_data)\n",
    "\n",
    "# draw the scatters\n",
    "color = ['yellowgreen','yellow','chartreuse','turquoise','orange','coral','salmon','darkgray','skyblue','mediumpurple']\n",
    "for j in range(len(low_data)):\n",
    "    \n",
    "    plt.scatter(a[j][0],a[j][1],c=color[labels[j]],s=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the first 2K training 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_data_file = open('train-images',\"rb\")\n",
    "label_file = open('train-labels',\"rb\")\n",
    "data_buff = original_data_file.read()\n",
    "label_buff = label_file.read()\n",
    "\n",
    "data_index = 0\n",
    "label_index = 0\n",
    "\n",
    "# read the magic, image numbers, rows, columns\n",
    "magicD, numImages , numRows , numColumns = struct.unpack_from('>IIII' , data_buff , data_index)\n",
    "data_index += struct.calcsize('>IIII')\n",
    "\n",
    "magicL, numLabels = struct.unpack_from('>II' , label_buff , label_index)    \n",
    "label_index += struct.calcsize('>II') \n",
    "\n",
    "\n",
    "data = np.zeros((2000,28*28))\n",
    "labels = []\n",
    "\n",
    "for i in range(2000):\n",
    "    # read data\n",
    "    im = struct.unpack_from('>784B',data_buff, data_index)\n",
    "    data_index += struct.calcsize('>784B')\n",
    "    im = np.array(im)\n",
    "    data[i]=im\n",
    "    \n",
    "    #read labels\n",
    "    la = struct.unpack_from('>1B',label_buff, label_index)   \n",
    "    label = la[0] \n",
    "    label_index += struct.calcsize('>1B')  \n",
    "    labels.append(label)  \n",
    "    \n",
    "low_data = PCA(data,3)\n",
    "a = np.array(low_data)\n",
    "\n",
    "ax = plt.figure().add_subplot(111, projection = '3d')  \n",
    "# draw the scatters\n",
    "\n",
    "for j in range(len(low_data)): \n",
    "    ax.scatter(a[j][0],a[j][1],a[j][2], c=color[labels[j]],s=5) #点为红色三角形  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis\n",
    "\n",
    "#### Phenomenon\n",
    "As shown above, the dots with the same color gathered together. But different colors may squeeze in a narrow area. Therefore we can't distinguish different numbers clearly.\n",
    "\n",
    "#### Analysis\n",
    "In order to show the results in picture, we reduce the data set to a 2-D. Of cource the data may lose some imformation and features. As a result, it get difficult to discern the numbers.\n",
    "\n",
    "### Improve\n",
    "We may extend the dimensions to remain more imformation and features.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
